"""
API for managing interactions with language models, including prompt completion and agent configuration.
"""
from typing import Optional
from fastapi import HTTPException

from oarc.base_api.base_tool_api import BaseToolAPI
from oarc.promptModel.multi_modal_prompting import MultiModalPrompting


class LLMPromptAPI(BaseToolAPI):
    """
    A FastAPI-based API for handling language model prompting functionality.
    This class provides endpoints for interacting with language models, 
    including sending prompts and optionally loading agent configurations 
    to customize the behavior of the language model. It serves as a wrapper 
    to facilitate seamless integration of language model capabilities into 
    applications.
    """


    def __init__(self):
        """
        Initialize the LLMPromptAPI instance with a predefined API prefix and tags.
        This sets up the base configuration for the API, including its routing details.
        """
        super().__init__(prefix="/api/llm", tags=["language-model"])
    
    def setup_routes(self):
        """
        Configure and define the API routes for handling language model prompting operations.
        This method sets up the necessary endpoints to enable interaction with the language model.
        """
        @self.router.post("/complete")
        async def complete(self, prompt: str, agent_id: Optional[str] = None):
            """
            Process a prompt completion request by interacting with the language model.
            
            This endpoint allows users to send a prompt to the language model and optionally 
            specify an agent configuration using the `agent_id`. If an `agent_id` is provided, 
            the corresponding agent configuration is loaded to customize the behavior of the 
            language model before processing the prompt.
            
            Args:
            prompt (str): The input prompt to be processed by the language model.
            agent_id (Optional[str]): An optional identifier for loading a specific agent 
                          configuration to customize the language model's behavior.
            
            Returns:
            dict: A dictionary containing the response generated by the language model.
            """
            try:
                prompt_handler = MultiModalPrompting()
                if agent_id:
                    # Load agent configuration
                    prompt_handler.agent = await prompt_handler.load_agent(agent_id)
                response = await prompt_handler.send_prompt(prompt)
                return {"response": response}
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))